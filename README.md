# TIE–Dialog Region-Based Pilot Evaluation 

This repository contains the full replication package for a region-based pilot evaluation of rupture and repair detection using TIE–Dialog. The study tests whether event regions derived directly from a coherence signal C(t) overlap with human-annotated rupture and repair regions beyond chance, using temporal overlap metrics and a random-region permutation baseline.

The core methodological contribution is the use of region-based evaluation (windows) rather than point-level matching, which is more appropriate given the temporal uncertainty of human event labeling.

What this repo contains

Notebook (main replication artifact)

notebook/region_evaluation.ipynb

Input data

data/tie_dialog_6_dialogues_combined.csv
(dialogue turns + coherence signal C(t))

data/valleys_peaks_final_results.xlsx
(human rupture/repair point annotations)

Outputs (generated by the notebook)

results/per_dialogue_model_vs_consensus_optionA.csv

results/per_dialogue_IAA_optionA.csv

results/per_dialogue_best_lag_optionA.csv

results/per_dialogue_baseline_optionA.csv

results/region_metrics_report_optionA.pdf


Method summary 
Human annotation processing

Five annotators labeled rupture (valley) and repair (peak-like) points.

Each point at turn t is converted into a fixed window:

[t−2, t+2]

A consensus reference is defined as turns covered by at least:

≥3/5 annotators

Model event extraction (from the signal only)

Model events are not taken from any explicit system labels. Instead, they are extracted directly from the coherence dynamics using pre-specified, dialogue-relative criteria:

Repair-like regions:

C(t) ≥ Q₀.₈₅(C)

Rupture-like regions:

dC(t) = C(t) − C(t−1)

dC(t) ≤ Q₀.₁₅(dC)

All quantiles are computed independently per dialogue.

Evaluation metrics

Intersection-over-Union (IoU) on temporal masks

overlap-based F1 on temporal masks

precision and recall (mask-based)

Baseline

A permutation baseline is computed using random regions matched to the model’s:

number of segments

segment lengths

The notebook runs B = 2000 permutations and reports p-values.

Lag scan (precursor analysis)

To test whether model events precede human-labeled events, the notebook performs a lag scan:

k ∈ [−5, +5]

reports best lag k* maximizing IoU

# How to run (Google Colab)

Open the notebook in Colab:

Upload notebook/region_evaluation_optionA.ipynb to Colab, or open it directly from GitHub.

Upload the two input files when prompted:

data/tie_dialog_6_dialogues_combined.csv

data/valleys_peaks_final_results.xlsx

Run all cells from top to bottom.

The notebook will generate all output tables and the PDF report automatically.

Expected outputs

After running, you should obtain:

Per-dialogue overlap results (model vs consensus)

Human–human agreement (IAA)

Random-region baseline results (IoU/F1 + p-values)

Best-lag results (k* and overlap at k*)

A PDF report summarizing the full evaluation

# Citation

If you use this repository or its evaluation protocol in academic work, please cite the associated preprint and/or the Zenodo release (DOI will be provided in the repository release).

# License

This project is licensed under the Apache License 2.0. See the LICENSE file for details.

# Contact

Adolfo J. Céspedes Jiménez - a.j.cespedes.jimenez(AT)student.rug.nl
(University of Groningen)
